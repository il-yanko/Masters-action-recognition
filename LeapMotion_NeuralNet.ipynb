{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# the length of records (if shorter, we need to add some zero rows)\n",
    "NUMBER_TIMESTEPS = 100\n",
    "# the number of features (from the data)\n",
    "NUMBER_FEATURES = 202\n",
    "# the number of classes of gestures\n",
    "NUMBER_OUTPUTS = 2\n",
    "# you can encode more than 1 but for this example we have binary output (circle/swipe)\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join, dirname, abspath\n",
    "\n",
    "mypath = 'C:/Users/iljan/Desktop/leap_motion/data'\n",
    "datafiles = [f for f in listdir('data') if isfile(join(mypath, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\circle1.csv\n",
      "data\\circle2.csv\n",
      "data\\circle3.csv\n",
      "data\\circle4.csv\n",
      "data\\circle5.csv\n",
      "data\\circle6.csv\n",
      "data\\circle7.csv\n",
      "data\\circle8.csv\n",
      "data\\circle9.csv\n",
      "data\\circle10.csv\n",
      "data\\swipe1.csv\n",
      "data\\swipe2.csv\n",
      "data\\swipe3.csv\n",
      "data\\swipe4.csv\n",
      "data\\swipe5.csv\n",
      "data\\swipe6.csv\n",
      "data\\swipe7.csv\n",
      "data\\swipe8.csv\n",
      "data\\swipe9.csv\n",
      "data\\swipe10.csv\n"
     ]
    }
   ],
   "source": [
    "# Define the number of circles and swipes\n",
    "num_files = 10\n",
    "\n",
    "# Use a loop to generate file names for circles\n",
    "circle = ['circle{}.csv'.format(i) for i in range(1, num_files + 1)]\n",
    "\n",
    "# Use a loop to generate file names for swipes\n",
    "swipe = ['swipe{}.csv'.format(i) for i in range(1, num_files + 1)]\n",
    "\n",
    "for c in circle:\n",
    "    relative_path = 'data\\\\' + c\n",
    "    print(relative_path)\n",
    "    tmp = pd.read_csv(relative_path)\n",
    "    tmp['GestureTypeCircle'] = 1\n",
    "    tmp['GestureTypeSwipe'] = 0\n",
    "    tmp.to_csv(path_or_buf=relative_path, index=False)\n",
    "\n",
    "for s in swipe:\n",
    "    relative_path = 'data\\\\' + s\n",
    "    print(relative_path)\n",
    "    tmp = pd.read_csv(relative_path)\n",
    "    tmp['GestureTypeCircle'] = 0\n",
    "    tmp['GestureTypeSwipe'] = 1\n",
    "    tmp.to_csv(path_or_buf=relative_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose data we need\n",
    "columns = ['handPalmPosition_X','handPalmPosition_Y','handPalmPosition_Z',\n",
    "          'pitch', 'roll', 'yaw', 'GestureTypeCircle', 'GestureTypeSwipe',\n",
    "          'wristPosition_X', 'wristPosition_Y','wristPosition_Z',\n",
    "          'elbowPosition_X', 'elbowPosition_Y', 'elbowPosition_Z']\n",
    "\n",
    "finger_names = ['Thumb', 'Index', 'Middle', 'Ring', 'Pinky']\n",
    "bone_names = ['Metacarpal', 'Proximal', 'Intermediate', 'Distal']\n",
    "    \n",
    "for finger in finger_names:\n",
    "    columns.append(finger + 'Length')\n",
    "    columns.append(finger + 'Width')\n",
    "\n",
    "for finger in finger_names:\n",
    "    for bone in bone_names:\n",
    "        columns.append(finger + bone + 'Start_X')\n",
    "        columns.append(finger + bone + 'Start_Y')\n",
    "        columns.append(finger + bone + 'Start_Z')\n",
    "        columns.append(finger + bone + 'End_X')\n",
    "        columns.append(finger + bone + 'End_Y')\n",
    "        columns.append(finger + bone + 'End_Z')\n",
    "        columns.append(finger + bone + 'Direction_X') \n",
    "        columns.append(finger + bone + 'Direction_Y') \n",
    "        columns.append(finger + bone + 'Direction_Z')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\circle1.csv\n",
      "size raw = (37, 204)\n",
      "size normalized =  (100, 204)\n",
      "data\\circle10.csv\n",
      "size raw = (60, 204)\n",
      "size normalized =  (100, 204)\n",
      "data\\circle2.csv\n",
      "size raw = (66, 204)\n",
      "size normalized =  (100, 204)\n",
      "data\\circle3.csv\n",
      "size raw = (39, 204)\n",
      "size normalized =  (100, 204)\n",
      "data\\circle4.csv\n",
      "size raw = (39, 204)\n",
      "size normalized =  (100, 204)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iljan\\AppData\\Local\\Temp\\ipykernel_20424\\201503229.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tmp = tmp.append(pd.Series(0, index=tmp.columns), ignore_index=True)\n",
      "C:\\Users\\iljan\\AppData\\Local\\Temp\\ipykernel_20424\\201503229.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tmp = tmp.append(pd.Series(0, index=tmp.columns), ignore_index=True)\n",
      "C:\\Users\\iljan\\AppData\\Local\\Temp\\ipykernel_20424\\201503229.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tmp = tmp.append(pd.Series(0, index=tmp.columns), ignore_index=True)\n",
      "C:\\Users\\iljan\\AppData\\Local\\Temp\\ipykernel_20424\\201503229.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tmp = tmp.append(pd.Series(0, index=tmp.columns), ignore_index=True)\n",
      "C:\\Users\\iljan\\AppData\\Local\\Temp\\ipykernel_20424\\201503229.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tmp = tmp.append(pd.Series(0, index=tmp.columns), ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\circle5.csv\n",
      "size raw = (78, 204)\n",
      "size normalized =  (100, 204)\n",
      "data\\circle6.csv\n",
      "size raw = (23, 204)\n",
      "size normalized =  (100, 204)\n",
      "data\\circle7.csv\n",
      "size raw = (80, 204)\n",
      "size normalized =  (100, 204)\n",
      "data\\circle8.csv\n",
      "size raw = (97, 204)\n",
      "size normalized =  (100, 204)\n",
      "data\\circle9.csv\n",
      "size raw = (67, 204)\n",
      "size normalized =  (100, 204)\n",
      "data\\swipe1.csv\n",
      "size raw = (84, 204)\n",
      "size normalized =  (100, 204)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iljan\\AppData\\Local\\Temp\\ipykernel_20424\\201503229.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tmp = tmp.append(pd.Series(0, index=tmp.columns), ignore_index=True)\n",
      "C:\\Users\\iljan\\AppData\\Local\\Temp\\ipykernel_20424\\201503229.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tmp = tmp.append(pd.Series(0, index=tmp.columns), ignore_index=True)\n",
      "C:\\Users\\iljan\\AppData\\Local\\Temp\\ipykernel_20424\\201503229.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tmp = tmp.append(pd.Series(0, index=tmp.columns), ignore_index=True)\n",
      "C:\\Users\\iljan\\AppData\\Local\\Temp\\ipykernel_20424\\201503229.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tmp = tmp.append(pd.Series(0, index=tmp.columns), ignore_index=True)\n",
      "C:\\Users\\iljan\\AppData\\Local\\Temp\\ipykernel_20424\\201503229.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tmp = tmp.append(pd.Series(0, index=tmp.columns), ignore_index=True)\n",
      "C:\\Users\\iljan\\AppData\\Local\\Temp\\ipykernel_20424\\201503229.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tmp = tmp.append(pd.Series(0, index=tmp.columns), ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\swipe10.csv\n",
      "size raw = (84, 204)\n",
      "size normalized =  (100, 204)\n",
      "data\\swipe2.csv\n",
      "size raw = (39, 204)\n",
      "size normalized =  (100, 204)\n",
      "data\\swipe3.csv\n",
      "size raw = (62, 204)\n",
      "size normalized =  (100, 204)\n",
      "data\\swipe4.csv\n",
      "size raw = (59, 204)\n",
      "size normalized =  (100, 204)\n",
      "data\\swipe5.csv\n",
      "size raw = (47, 204)\n",
      "size normalized =  (100, 204)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iljan\\AppData\\Local\\Temp\\ipykernel_20424\\201503229.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tmp = tmp.append(pd.Series(0, index=tmp.columns), ignore_index=True)\n",
      "C:\\Users\\iljan\\AppData\\Local\\Temp\\ipykernel_20424\\201503229.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tmp = tmp.append(pd.Series(0, index=tmp.columns), ignore_index=True)\n",
      "C:\\Users\\iljan\\AppData\\Local\\Temp\\ipykernel_20424\\201503229.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tmp = tmp.append(pd.Series(0, index=tmp.columns), ignore_index=True)\n",
      "C:\\Users\\iljan\\AppData\\Local\\Temp\\ipykernel_20424\\201503229.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tmp = tmp.append(pd.Series(0, index=tmp.columns), ignore_index=True)\n",
      "C:\\Users\\iljan\\AppData\\Local\\Temp\\ipykernel_20424\\201503229.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tmp = tmp.append(pd.Series(0, index=tmp.columns), ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\swipe6.csv\n",
      "size raw = (99, 204)\n",
      "size normalized =  (100, 204)\n",
      "data\\swipe7.csv\n",
      "size raw = (92, 204)\n",
      "size normalized =  (100, 204)\n",
      "data\\swipe8.csv\n",
      "size raw = (51, 204)\n",
      "size normalized =  (100, 204)\n",
      "data\\swipe9.csv\n",
      "size raw = (99, 204)\n",
      "size normalized =  (100, 204)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iljan\\AppData\\Local\\Temp\\ipykernel_20424\\201503229.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tmp = tmp.append(pd.Series(0, index=tmp.columns), ignore_index=True)\n",
      "C:\\Users\\iljan\\AppData\\Local\\Temp\\ipykernel_20424\\201503229.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tmp = tmp.append(pd.Series(0, index=tmp.columns), ignore_index=True)\n",
      "C:\\Users\\iljan\\AppData\\Local\\Temp\\ipykernel_20424\\201503229.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tmp = tmp.append(pd.Series(0, index=tmp.columns), ignore_index=True)\n",
      "C:\\Users\\iljan\\AppData\\Local\\Temp\\ipykernel_20424\\201503229.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tmp = tmp.append(pd.Series(0, index=tmp.columns), ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "x = []\n",
    "# Labels\n",
    "y = []\n",
    "\n",
    "for sample in datafiles:\n",
    "    relative_path = 'data\\\\' + sample\n",
    "    # print(relative_path)\n",
    "    tmp = pd.read_csv(relative_path, usecols=columns)\n",
    "    \n",
    "    # Normalize the size of sample (LSTM requires all inputs of the same size)\n",
    "    print('{}\\nsize raw = {}'.format(relative_path,tmp.shape))\n",
    "    while tmp.shape[0] < NUMBER_TIMESTEPS:\n",
    "        tmp = tmp.append(pd.Series(0, index=tmp.columns), ignore_index=True)\n",
    "    if tmp.shape[0] > NUMBER_TIMESTEPS:\n",
    "        tmp = tmp.head(100)\n",
    "    print('size normalized = ',tmp.shape)\n",
    "    \n",
    "    #tmp_x = tmp.loc[:, tmp.columns != 'GestureTypeCircle','GestureTypeSwipe']\n",
    "    \n",
    "    tmp_x = tmp[[column for column in list(tmp.columns)\n",
    "                 if column != 'GestureTypeCircle' \n",
    "                 and column != 'GestureTypeSwipe']]\n",
    "    tmp_y = tmp[['GestureTypeCircle', 'GestureTypeSwipe']]\n",
    "        \n",
    "    x.append(tmp_x)\n",
    "    y.append(tmp_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(y[0].loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "# Each sample requires labels of [1,NUMBER_OUTPUTS] size (not a list)\n",
    "y_new = list()\n",
    "for cur_label in y:\n",
    "    tmp = np.array(cur_label.loc[0])\n",
    "    y_new.append(tmp)\n",
    "y = np.array(y_new)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train samples = 14\n",
      "Number of test samples = 6\n",
      "There is  <class 'list'>  of  <class 'pandas.core.frame.DataFrame'>\n",
      "The list was turned into <numpy.ndarray>\n"
     ]
    }
   ],
   "source": [
    "# Set a percentage of test set fraction\n",
    "test_percent = 30\n",
    "\n",
    "# Divide data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=test_percent/100, shuffle=True)\n",
    "len_train = len(X_train)\n",
    "len_test = len(X_test)\n",
    "\n",
    "print ('Number of train samples = {}\\nNumber of test samples = {}'.format(len_train, len_test))\n",
    "print ('There is ',type(X_train),' of ',type(X_train[0]))\n",
    "\n",
    "# Turn list(DataFrame) into numpy.ndarray with [len_train, NUMBER_TIMESTEPS, NUMBER_FEATURES]\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "print('The list was turned into <numpy.ndarray>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def build_model(cur_batch_size):\n",
    "    model = models.Sequential()    \n",
    "    # an input layer that expects:\n",
    "    # 1 or more samples, NUMBER_TIMESTEPS time steps and NUMBER_FEATURES features.\n",
    "    model.add(layers.LSTM( 256, return_sequences=True, input_shape=(NUMBER_TIMESTEPS, NUMBER_FEATURES)) )\n",
    "    model.add(layers.LSTM( 256, input_shape=(NUMBER_TIMESTEPS, NUMBER_FEATURES)) )\n",
    "    \n",
    "    # Hidden fully connected layers of the neural network\n",
    "    model.add(layers.Dense(512,activation='relu'))  \n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(256,activation='relu'))    \n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(512,activation='relu'))\n",
    "    \n",
    "    # Classification layer of the neural network\n",
    "    model.add(layers.Dense(NUMBER_OUTPUTS, activation='softmax'))\n",
    "    \n",
    "    opt = Adam(learning_rate=0.002)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_model(trainX, trainy, testX, testy, cur_batch_size): \n",
    "    verbose, epochs, batch_size  = 2, 10, cur_batch_size    \n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "    loss, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=verbose)\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 100, 256)          470016    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 256)               525312    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               131584    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               131584    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,390,850\n",
      "Trainable params: 1,390,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 - 1s - loss: 0.0340 - accuracy: 1.0000 - 1s/epoch - 1s/step\n",
      ">experiment#1: test loss = 0.03403, test accuracy = 100.00%\n",
      "1/1 - 0s - loss: 0.0097 - accuracy: 1.0000 - 50ms/epoch - 50ms/step\n",
      ">experiment#2: test loss = 0.009657, test accuracy = 100.00%\n",
      "1/1 - 0s - loss: 0.3441 - accuracy: 0.8333 - 50ms/epoch - 50ms/step\n",
      ">experiment#3: test loss = 0.3441, test accuracy = 83.33%\n",
      "1/1 - 0s - loss: 2.5050 - accuracy: 0.8333 - 48ms/epoch - 48ms/step\n",
      ">experiment#4: test loss = 2.505, test accuracy = 83.33%\n",
      "1/1 - 0s - loss: 0.6948 - accuracy: 0.3333 - 50ms/epoch - 50ms/step\n",
      ">experiment#5: test loss = 0.6948, test accuracy = 33.33%\n"
     ]
    }
   ],
   "source": [
    "# repeat experiment\n",
    "repeats = 5\n",
    "model = build_model(len_train)\n",
    "\n",
    "for r in range(repeats):\n",
    "    results = evaluate_model(X_train, y_train, X_test, y_test, len_train)\n",
    "    print('>experiment#{}: test loss = {:1.4}, test accuracy = {:2.2%}'.format(\n",
    "        r+1, results[0], results[1]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
